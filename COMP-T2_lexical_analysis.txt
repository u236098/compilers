
--- Page 1 ---
COMP  - 1.- Compilers Lexical Analysis 
Lexical Analysis 
Dolors Sala 
--- Page 2 ---
COMP  - 2.- Compilers Lexical Analysis 
Bibliography 
These slides are taken from the following slide lectures 
‚Ä¢Fredrik Kjolstad, Compilers  CS143, Stanford University (Lectures 3 and 4) 
‚Ä¢Henri Casanova, Machine learning and systems programming ICS312 (Module 9 Compiling), University of Hawaii (Lexing Lecture) 
‚Ä¢Yannis Smaragdakis, Compilers K31, University of Athens, Lecture 3 
--- Page 3 ---
COMP  - 3.- Compilers Lexical Analysis 
Lexical Analysis 
‚Ä¢Identify the words in the input stream 
‚Ä¢In linguistics the lexical analysis is to identify correct words 
‚ÄìThe correct words are listed at the dictionary 
‚Ä¢The compiler with the lexical analysis does 
‚ÄìIdentifies the words (in the input code) 
‚ÄìBuilds the table (dictionary) of keywords and new 
identifiers (variable declarations, functions‚Ä¶) 
--- Page 4 ---
COMP  - 4.- Compilers Lexical Analysis 
Lexical Analyzer: Definition 
‚Ä¢Lexical analyzer translates the input code into a form 
more usable to the rest of the compiler 
‚Ä¢It does two things: 
‚ÄìTransforms the input source code into a sequence of substrings 
‚ÄìClassifies them according to their role or syntactic category 
‚Ä¢The input is the source code 
‚Ä¢The output is a list of substrings called tokens 
‚Ä¢Lexical analysis is also called lexing or scanning 

--- Page 5 ---
COMP  - 5.- Compilers Lexical Analysis 
Token 
‚Ä¢AToken is an indivisible lexical unit (a lexeme) 
classified according to syntactic categories 
‚Ä¢Lexeme :
‚ÄìKeywords and special characters: 
‚Ä¢if, while, for,.. 
‚Ä¢+ - / : > < >> < ‚Ä¶ 
‚ÄìNames and numbers 
‚Ä¢(Syntactic) Category : identifier, integer, floating-point 
number, operator, keyword‚Ä¶ 
--- Page 6 ---
COMP  - 6.- Compilers Lexical Analysis 
Lexical Analysis Terms 
‚Ä¢AToken is an indivisible lexical unit (a lexeme) 
classified according to syntactic categories 
‚Ä¢Lexeme is the string that represents an instance of a 
token 
‚Ä¢Pattern is the description of the form that represents all 
possible lexemes a token can take 
Example: 
Token            Pattern (informal description)   Sample lexemes 
--- Page 7 ---
COMP  - 7.- Compilers Lexical Analysis 
Lexical Analysis Terminology Examples 
C example: 
printf(‚ÄúHello %s\n‚Äù, name); 
Tokens?
(printf, id) (‚ÄúHello %s\n‚Äù, literal) (name, id) 
How about ( , ; ) ?             
Token            Pattern (informal description)   Sample lexemes 
They are also tokens, we‚Äôll see full specification 
--- Page 8 ---
COMP  - 8.- Compilers Lexical Analysis 
The lookahead Problem 
‚Ä¢The lexer has to process the source code character by 
character in order and identify the lexemes 
‚Ä¢Just looking at the current character is not enough  to 
determine if the lexeme is finished 
Example: in c, = vs == or i vs int 
In this case we need to check the next character to decide one or the other, this means a lookahead of 1, but‚Ä¶ beginner vs begin? 
‚Ä¢The lookahead is the amount of characters we need to 
look to correctly distinguish all possible lexemes of a 
language 
‚ÄìEach language may have a different lookahead 
‚ÄìLanguages should require ‚Äúsmall‚Äù lookaheads 
--- Page 9 ---
COMP  - 9.- Compilers Lexical Analysis 
Non-essential Characters 
‚Ä¢The lexical analysis neglects non-essential charact ers 
‚ÄìSpaces, tabs, linefeeds 
‚ÄìComments 
‚Ä¢The lexer should allow arbitrary number of these non -
essential characters in the input (source code) 
‚Ä¢Input example: 
main(){ 
int x = 0; 
}
Seen as a single string of characters: main(){\n\tint x = 0;\n}\n
--- Page 10 ---
COMP  - 10.- Compilers Lexical Analysis 
Lexical Analysis: Example (cont.) 
‚Ä¢Input example: 
main(){ 
int x = 0; 
}
The input is just a single string of characters: 
main(){\n\tint x = 0;\n}\n
Tokenization: 
(main , key)(‚Äú (‚Äù,op) (‚Äú )‚Äù,op) (‚Äú {‚Äù,op) ( int , key)( x, id) (‚Äú =‚Äù,op) (‚Äú ;‚Äù,op)
(‚Äú }‚Äù,op)
We‚Äôll see the exact specification of tokens format. 
--- Page 11 ---
COMP  - 11.- Compilers Lexical Analysis 
Lexer Specification 
‚Ä¢How to formalize the lexer‚Äôs job to recognize the to kens 
of a specific language? 
‚Ä¢We need a language: the language of tokens 
‚Ä¢A language is specified with two components: 
‚ÄìAn alphabet denoted as Œ£
‚Ä¢Example: ASCII 
‚ÄìThe subset of all possible strings over Œ£ (dictionary) 
‚Ä¢Language of tokens -- specify which strings are toke ns 
‚ÄìIt can be specified with regular expressions 
--- Page 12 ---
COMP  - 12.- Compilers Lexical Analysis 
Examples of Languages 
Alphabet = English characters Slight differences with Catalan/Spanish Big differences with Chinese, Arabic Language = English sentences 
Not every string of English 
characters is an English sentence Alphabet = ASCII Language = c programs 
Not every ASCII 
combination of characters is a correct c line of code 
--- Page 13 ---
COMP  - 13.- Compilers Lexical Analysis 
Regular Expressions 
‚Ä¢Languages are sets of strings 
‚Ä¢Need a formal notation for specifying which ones 
‚Ä¢The standard notation for regular languages is the regular expressions 
‚Ä¢A regular expression (RE) is a string (in a meta-
language) that describes a pattern (in the token la nguage) 
‚ÄìThe regular expression has a notation/language so it is a language to describe a language (meta-language) 
--- Page 14 ---
COMP  - 14.- Compilers Lexical Analysis 
Regular Expressions Specification 
Atomic regular expressions 
‚Ä¢Single character: ‚Äòc‚Äô = {‚Äúc‚Äù} 
‚Ä¢Epsilon : Œµ = {‚Äú‚Äù} The empty string (a string with 0 
characters 
Compound regular expressions If A and B are regular 
expressions over and alphabet ‚àë 
‚Ä¢Union (+): A + B = {s | s œµ A or s œµ B} 
‚Ä¢Concatenation : AB = {ab | a œµ A and b œµ B} 
‚Ä¢Iteration (*) : A* = ‚ãÉ  where Ai = AA‚Ä¶A  i times 
--- Page 15 ---
COMP  - 15.- Compilers Lexical Analysis 
More Regular Expressions Notation 
Symbol Meaning Example + Union (one or another) a + b ÔÉ†a or b
* Zero or more times a* + (a +) One or more times a+ÔÉ†aa* 
? Optional (zero or one time) b?a* ÔÉ†ba* + a* 
[] Character class [0-9] any digit 
[a-zA-Z_] any lower or upper case letter or underscore 
?! (?!pattern) Negative lookahead (?!aa)a* 
Any number of a‚Äôs except aa 
Useful notation for the P2 Lexer 
--- Page 16 ---
COMP  - 16.- Compilers Lexical Analysis 
Examples of Regular Expressions (I) 
‚Ä¢Regular expressions are common in our day-to-day li fe 
‚Ä¢Phone numbers: (93)543-2333 
‚Äì‚àë= 
 ‚ãÉ{ ‚Äò-‚Äô, ‚Äò(‚Äô,‚Äò)‚Äô} 
‚Äìexchange = digits 2
‚Äìarea = digits 3
‚Äìphone = digits 4
‚Äìphone number = ‚Äò(‚Äò + exchange + ‚Äò)‚Äô + area + ‚Äò-‚Äô + pone 
Note the difference between a meta-character (a character 
of the language to define regular expressions) and a 
character of the alphabet: +34(93)543-2333 
--- Page 17 ---
COMP  - 17.- Compilers Lexical Analysis 
Examples of Regular Expressions (II) 
‚Ä¢Email Addresses: dolors@upf.edu 
‚Äì‚àë=  ‚ãÉ{ ‚Äò.‚Äô, ‚Äò@‚Äô} 
‚Äìname = letter + 
‚Äìaddress = name + ‚Äò@‚Äô + name + ‚Äò.‚Äô + name 
‚Ä¢Can it recognize the email: dolors.sala@upf.edu ?
‚Äìname = letter + + (‚Äò.‚Äô + letter +)*
‚Ä¢Can it recognize the email: dolors2022@upf.edu ?
‚Äì‚àë=  ‚ãÉ
  ‚ãÉ{ ‚Äò.‚Äô, ‚Äò@‚Äô} 
‚Äìname = identifier + + ‚Äò@‚Äô + (‚Äò.‚Äô + identifier +)*
‚Ä¢Can it recognize any email address? Defined in previous slides: letter = ‚ÄòA‚Äô + ‚ÄòB‚Äô + ‚Ä¶ + ‚ÄòZ‚Äô + ‚Äòa‚Äô + ‚Äòb‚Äô + ‚Ä¶ + ‚Äòz‚Äô
Defined in previous slides:digit = [0-9] 
+ 
identifier = letter (letter + digit)* 
--- Page 18 ---
COMP  - 18.- Compilers Lexical Analysis 
Notation: Tokens in regular expressions 
‚Ä¢We describe tokens in regular expressions 
‚Ä¢Keyword : ‚Äúint‚Äù or ‚Äúbegin‚Äù or ‚Äúelse‚Äù or ‚Ä¶ 
(Abbreviation: ‚Äòint‚Äô = ‚Äòi‚Äô+ ‚Äòn‚Äô+ ‚Äòt‚Äô) 
‚Ä¢Integers : a non-empty string of digits 
‚Äì‚àë = [0-9] 
‚Äìdigit = [0-9] 
‚Äìinteger = digit +
‚Ä¢Identifier : strings of letters or digits, starting with a let ter 
‚Äì‚àë = [a-zA-Z0-9]
‚Äìletter = [a-zA-Z] 
‚Äìidentifier = letter (letter + digit)* 
‚Ä¢Whitespace : a non-empty sequence of blank spaces, 
newlines and tabs: (‚Äò ‚Äô + ‚Äò\n‚Äô + ‚Äò\t‚Äô) +
--- Page 19 ---
COMP  - 19.- Compilers Lexical Analysis 
Regular Expressions in SW 
‚Ä¢Grep: Linux utility to identify a string in a file 
‚Ä¢Perl Shell: program that process a text file applyi ng a set 
of define string matching rules 
‚Ä¢Text editors apply regular expressions for string replacements 
‚Ä¢Many programs have the need to identify patterns an d 
use regular expressions internally, including compi lers 
‚Ä¢Not a unified syntax of regular expressions: Each one has 
its own 
--- Page 20 ---
COMP  - 20.- Compilers Lexical Analysis 
REs Implementation: Finite Automata 
‚Ä¢How do we use the regular expressions (REs) to pars e 
the input source code and generate the token stream ? 
‚Ä¢Regular expressions denote the (regular) language 
‚Ä¢Regular languages are recognized by Finite Automata
‚Ä¢Therefore we implement the language defined by a regular expression implementing the corresponding automata 
--- Page 21 ---
COMP  - 21.- Compilers Lexical Analysis 
Implementation of lexical Analysis 
‚Ä¢Specify lexical structure in regular expressions 
‚Ä¢Transform it to a finite automata 
‚ÄìDeterministic finite automata DFA 
‚ÄìNon-deterministic finite automata NFA 
‚Ä¢Implementation of regular expressions 

--- Page 22 ---
COMP  - 22.- Compilers Lexical Analysis 
Regular expressions ‚Äúoutput‚Äù 
‚Ä¢We can verify if a string belong to the language specified by the regular expression 
‚ÄìTrue/false answer 
‚Ä¢We need the tokens as the answer 
--- Page 23 ---
COMP  - 23.- Compilers Lexical Analysis 
Finite Automata 
(Implementation of regular 
expressions) 
A regular expression is implemented with 
an automaton 
--- Page 24 ---
COMP  - 24.- Compilers Lexical Analysis 
Automatic Lexer Construction 
‚Ä¢To convert a specification into code: 
1. Write down the RE for the input language 
2. Build a big NFA 
3. Build the DFA that simulates the NFA 
4. Systematically shrink the DFA 
5. Implement the DFA 
‚Ä¢Lexer generators 
‚ÄìLex and flex work along these lines 
‚ÄìAlgorithms are well-known and well-understood 
‚Ä¢In P2, we do some steps manually and create a gener ic 
engine to implement the automata as decided in each  
solution (one or many, DFA or NFA) 
‚ÄìThe automata are language specification provided as input 
--- Page 25 ---
COMP  - 25.- Compilers Lexical Analysis 
Finite Automata 
‚Ä¢Regular expressions = specification 
‚Ä¢Finite automata = implementation 
‚Ä¢A finite automaton is defined by 
‚ÄìAn input alphabet ‚àë 
‚ÄìA set of states S
‚ÄìA start state n (only one state from the set S) 
‚ÄìA set of accepting states F (a subset of S, F ‚äÜ S) 
‚ÄìA set of transitions between states: subset of SxS 
--- Page 26 ---
COMP  - 26.- Compilers Lexical Analysis 
Transition notations 
state: input ÔÉ†state state ÔÉ†input state 
s1: a ÔÉ†s2 s1ÔÉ†as2
Both mean: if automaton is in state s 1, reading a 
character ‚Äòa‚Äô in the input takes the automaton in s tate s 2
(we will use both indistinctively) If when reaching the end of input, the automaton is in an accepting state => 
accept the input; otherwise reject it
--- Page 27 ---
COMP  - 27.- Compilers Lexical Analysis 
Finite Automata as Graphs 
A state (state s) 
The start state (state n) 
An accepting state (state s) 
A transition (from state s1 to 
state s2 with the a input) 

--- Page 28 ---
COMP  - 28.- Compilers Lexical Analysis 
Automaton Example (I) 
‚Ä¢What input does the following automaton accept? 
It accepts the word ‚Äúif‚Äù 

--- Page 29 ---
COMP  - 29.- Compilers Lexical Analysis 
Automaton Example (II) 
‚Ä¢What input does the following automaton accept? 
It accepts the word 1 

--- Page 30 ---
COMP  - 30.- Compilers Lexical Analysis 
Automaton Example (III) 
‚Ä¢What input does the following automaton accept? 
It accepts all strings that finish with 00 ==> regular expression? 
(1+0)*00 
--- Page 31 ---
COMP  - 31.- Compilers Lexical Analysis 
Lexical Analysis 
Can we always represent a regular expression with a n 
automaton? If we write a piece of code that implements 
arbitrary 
automata we have a generic piece of code (an engine) 
that implements arbitrary regular expressions YES! 
This is a lexer!
--- Page 32 ---
COMP  - 32.- Compilers Lexical Analysis 
Œµ-Transitions 
The epsilon (Œµ) transitions can move the automata fr om 
state to state without consuming any input 
state: Œµ ÔÉ†state state ÔÉ†Œµstate 
Defines a non-deterministic finite automata (NFA) where there can be 
multiple possible transitions from a 
given input symbol at a state 
a*b*c*d*e 

--- Page 33 ---
COMP  - 33.- Compilers Lexical Analysis 
DFA vs NFA Example 
NFA: a*b*c*d*e 
DFA? Œµn s1 s2 s3 s4 b c d
Œµ Œµa
e
Any regular language can be defined by either NFA &  DFA b
s4 b c d
c da
e
edd
n s1 s2 s3 
eec
--- Page 34 ---
COMP  - 34.- Compilers Lexical Analysis 
Deterministic and Non-deterministic FA ‚Ä¢
A deterministic finite automata DFA is defined as an 
automaton that can only have one transition per inp ut 
symbol per state 
‚ÄìIt can take just one path at any given time for a particular input 
‚ÄìAccept the input if at the end of the input the automaton is at one accepting state 
‚Ä¢Non-deterministic finite automata NFA is defined as an 
automaton that can have zero (Œµ), one, or multiple 
transitions per input symbol per state :
‚ÄìThe NFA automaton have to keep track of multiple paths 
simultaneously 
‚ÄìAccept the input if at the end of the input the automaton is at 
least at one accepting state 
--- Page 35 ---
COMP  - 35.- Compilers Lexical Analysis 
DFA vs NFA Properties 
‚Ä¢Both can describe the same set of languages (regula r 
languages) 
‚Ä¢DFAs are faster to execute (as there are no choices  to 
consider) 
‚Ä¢For some given languages the NFA can be simpler tha n 
DFA 
‚Ä¢DFA can be exponentially larger than NFA 
--- Page 36 ---
COMP  - 36.- Compilers Lexical Analysis 
Convert Regular Expressions to NFAs 
‚Ä¢For each regular expression, define an NFA 
‚Ä¢Thompson‚Äôs construction (idea in 1968): systematically 
convert regular expressions (REs) into a finite sta te 
automata 
‚Ä¢Key idea: Define a Finite Automata ‚Äúpattern‚Äù for each RE 
operator 
‚ÄìStart with atomic REs, build up a big NFA 
‚Ä¢Notation: NFA for regular expression M 

--- Page 37 ---
COMP  - 37.- Compilers Lexical Analysis 
Thompson‚Äôs construction 
‚Ä¢For each atomic regular expression, define an NFA 
‚Ä¢Notation: NFA for regular expression M 
‚Ä¢For Œµ
‚Ä¢For input a 
‚Ä¢For AB 
‚Ä¢For A+B 

--- Page 38 ---
COMP  - 38.- Compilers Lexical Analysis 
Thompson‚Äôs construction II 
‚Ä¢For Œµ
‚Ä¢For input a 
‚Ä¢For AB 
‚Ä¢For A+B 
‚Ä¢For A* 

--- Page 39 ---
COMP  - 39.- Compilers Lexical Analysis 
Example of RegExp to NFA conversion I 
‚Ä¢Regular Expression: (1+0)*1 
0
1Œµ
Œµ ŒµŒµ 1+0 
A+B 
--- Page 40 ---
COMP  - 40.- Compilers Lexical Analysis 
Example of RegExp to NFA conversion II 
‚Ä¢Regular Expression: (1+0)*1 
0
1Œµ
Œµ ŒµŒµ1+0 
A* (1+0)* 
Œµ Œµ
ŒµŒµ
--- Page 41 ---
COMP  - 41.- Compilers Lexical Analysis 
Example of RegExp to NFA conversion III 
‚Ä¢Regular Expression: (1+0)*1 
1
0
1Œµ
Œµ ŒµŒµŒµ
ŒµŒµ (1+0)* 
Œµ(1+0)*1 
AB 
--- Page 42 ---
COMP  - 42.- Compilers Lexical Analysis 
Example of RegExp to NFA conversion IV 
‚Ä¢Regular Expression: (1+0)*1 
1
0
1Œµ
Œµ ŒµŒµŒµ
ŒµŒµ (1+0)* 
Œµ(1+0)*1 
--- Page 43 ---
COMP  - 43.- Compilers Lexical Analysis 
Example of RegExp to NFA conversion IV 
‚Ä¢Regular Expression: (1+0)*1 
‚Ä¢A human can define a simple NFA, however, this is a  
systematic approach for (automatic) implementation 
‚ÄìThe next step is to reduce it (systematically too) 
0
1Œµ
Œµ ŒµŒµ
Œµ
ŒµŒµ(1+0)* 
Œµ(1+0)*1 
A BC
DE
FŒµ
G H I J1
J
--- Page 44 ---
COMP  - 44.- Compilers Lexical Analysis 
Step 2: From NFA to DFA 
‚Ä¢Each state of DFA corresponds to a non-empty subset  of 
states of NFA 
‚Ä¢Starting state of the DFA is an state that contains all 
states of the NFA that are starting state and can b e 
reached from the starting state with Œµ-transitions 
‚ÄìFrom A state can be reached BCDHI states ÔÉ†state 1 of DFA 
‚Ä¢Add a transition SÔÉ†aS‚Äô in a DFA state iff:
‚ÄìS‚Äô is the set of NFA states reachable from any state in S a fter 
seeing the input a, considering Œµ-transitions also 
‚Ä¢From state 1 with a 0 it goes to state 2 which corr esponds in being in 
FGHIABCD 
‚Ä¢From state 1 with a 1 it goes to state 3 which corr esponds being in 
EGHIJABCD (this is also a final state) 
‚Ä¢Final DFA states are those DFA states which includes at 
least one NFA final state 
‚ÄìState 3 is final because is the only one including state J 
--- Page 45 ---
COMP  - 45.- Compilers Lexical Analysis 
Example NFA to DFA 
1
0Œµ
Œµ ŒµŒµ
Œµ
ŒµŒµ
ŒµA BC
DE
FŒµ
G H I J1
J
12
31200
0
1
131
--- Page 46 ---
COMP  - 46.- Compilers Lexical Analysis 
Implementation 
‚Ä¢A DFA can be implemented by a 2D Table T 
‚ÄìOne dimension is the states 
‚ÄìOther dimension is the input symbol 
‚ÄìFor every transition S iÔÉ†aSjdefine T[i, a] = k 
‚Ä¢DFA execution: 
‚ÄìIf in state S iand input a, read T[i, a] = k and go to state Sk
0 1
1 2 32 2 33 2 31200
0
1
131
--- Page 47 ---
COMP  - 47.- Compilers Lexical Analysis 
Implementation 
‚Ä¢NFA to DFA conversion is the heart of tools such as  
flex 
‚Ä¢But DFAs can be huge 
‚Ä¢In practice flex-like tools trade off speed for spa ce in the 
choice of NFA and DFA implementation 
--- Page 48 ---
COMP  - 48.- Compilers Lexical Analysis 
Implementing a Lexer 
1. Define the regular expressions for each token categ ory 
2. Define an NFA for each RE 
3. Convert the NFA (automatically) to a DFA 
4. Write the code to implement the DFA 
1. Implement the transition table 
5. Implement your lexer as a set of DFAs 
All these steps have to be generic engines to apply the 
translation automatically to each input code. These steps have been understood for decades and no w 
there are the automatic lexer tools (lex, flex) We don‚Äôt implement all these automatic steps in prac tices 
--- Page 49 ---
COMP  - 49.- Compilers Lexical Analysis 
Lexer Implementation 
Two approaches: 
‚Ä¢By hand : code by hand the lexer (in this course) 
‚ÄìStart with the description for the lexemes of each token, and derive the automata of the language 
‚ÄìWrite code to identify each occurrence of each lexeme on the output to return the list of tokens identified 
‚Ä¢Write a generic engine that runs (NFA or DFA) autom ata 
‚Ä¢Automatically : use a lexer generator (not in this course) 
‚ÄìSpecify the lexeme patterns to a lexical-analyzer generator 
‚Ä¢Write the engine that automatically identifies the automata based on the 
language description 
‚ÄìCompile those patterns into code that works as lexical analyzer 
‚Ä¢Write the generic engine that runs the automata (as  identified 
automatically) 
--- Page 50 ---
COMP  - 50.- Compilers Lexical Analysis 
Summary 
‚Ä¢The lexical analyzer identifies the lexemes (vocabulary) 
of the input and encodes them in tokens (lexeme, 
category) 
‚Ä¢The identification of lexemes is done defining the 
regular expression that defines them 
‚Ä¢Regular expressions are implemented by automata 
‚ÄìNFA ‚Äì non-deterministic finite automata 
‚ÄìDFA ‚Äì deterministic finite automata 
‚Ä¢Lexical analysis process 
‚ÄìDefine: alphabet , possible strings (dictionary - table of tokens) 
‚ÄìDefine the Regular Expressions for each acceptable lexeme 
‚ÄìDefine the DFA that represent the REs (you may need to first define NFA and transform it to DFA) 
‚ÄìImplement the DFA for each regular expression 
‚ÄìExecute the DFA with an input to get the tokens or errors 